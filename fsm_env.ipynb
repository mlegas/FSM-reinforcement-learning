{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment exceptions and helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSM Environment Exceptions\n",
    "These exceptions are thrown in case of incorrect transition/state properties of the FSM in the CSV file during the initialization and operation of the custom gym environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSMStartStateNotFoundError(Exception):\n",
    "    \"\"\"\n",
    "    This exception ensures that the FSM loaded from the CSV file has any start states in case a preset one has not been provided.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        print(\"ERROR: No start states have been found in the CSV file!\")\n",
    "        print(\"Please recheck the file and set at least a single start state.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSMTransitionStateNotFoundError(Exception):\n",
    "    \"\"\"\n",
    "    This exception is thrown in case the CSV file does not contain a state that the environment was meant to transition to.\n",
    "    \"\"\"\n",
    "    def __init__(self, unique_id):\n",
    "        print(\"ERROR: The transition to a state of the unique ID: {} has failed due to the state not being found in the CSV file!\".format(unique_id))\n",
    "        print(\"If this was not expected, please check the CSV file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSMIncorrectPresetStartStateError(Exception):\n",
    "    \"\"\"\n",
    "    This exception ensures that a correct preset state has been provided (or if it actually exists in the CSV file).\n",
    "    \"\"\"\n",
    "    def __init__(self, unique_id):\n",
    "        print(\"ERROR: The provided preset start state of the unique ID {} has not been found in the CSV file, or is not set as a start state.\".format(unique_id))\n",
    "        print(\"Please change the preset ID or set the state to be a start state in the CSV file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV File Exceptions\n",
    "These exceptions are thrown in case of data errors in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVFileTransitionsError(Exception):\n",
    "    \"\"\"\n",
    "    This exception ensures that the FSM loaded from the CSV file has a correct amount of transitions.\n",
    "    \"\"\"  \n",
    "    def __init__(self, list_of_states):\n",
    "        print(\"ERROR: States of the following Unique IDs have at least one of the following errors:\")\n",
    "        print(\"A. The amount of states in the 'Transitions_to_states' field is not equal to the amount of actions in the 'Possible_discrete_actions_(transitions)' field.\")\n",
    "        print(\"B. The amount of states in the 'Transitions_to_states' field is not equal to the amount of transitions in the 'Transition_names' field.\")\n",
    "        print(\"C. The amount of actions in the 'Possible_discrete_actions_(transitions)' field is not equal to the amount of transitions in the 'Transition_names' field.\")\n",
    "        print(*list_of_states)\n",
    "        print(\"Please recheck the states and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVFileEmptyValues(Exception):\n",
    "    \"\"\"\n",
    "    This exception is thrown in case it contains empty values in at least one row.\n",
    "    \"\"\"\n",
    "    def __init__(self, list_of_rows):\n",
    "        print(\"ERROR: The following rows of the CSV file provided contain empty values:\")\n",
    "        print(*list_of_rows)\n",
    "        print(\"Please recheck the CSV file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for pre-eliminary testing of the loaded CSV file\n",
    "The following functions and exception help to prepare the CSV file for later use. However, they serve more as helpers rather than Q&A bug-testing methods, since they will not detect a CSV file broken beyond anything of quick repair, for example when there are mistyped types (i.e. the row 'Unique_ID' having a value of \"UniqueID#01\" instead of 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def convert_state_names(file_name:str) -> None:\n",
    "    \"\"\"\n",
    "    This function adds discretized state names in case the CSV file provided does not contain such a column.\n",
    "    \n",
    "    Example: On -> 1, Off -> 2, Reset -> 3, On -> 1 \n",
    "\n",
    "    Warning: Although Pandas will by default load the CSV file in chunks to help with large file sizes, it might still crash when used on files of excessive file size (above available memory size).\n",
    "    \n",
    "    :param file_name: The file name of the CSV file.\n",
    "    \"\"\"\n",
    "    df = pandas.read_csv(file_name, low_memory=True, memory_map=True)\n",
    "\n",
    "    if 'Discretized_state_name' not in df.columns:\n",
    "        state_names_dict = {}\n",
    "        counter = 1\n",
    "        # We use itertuples here as it is the fastest way of iterating row by row in a Pandas dataframe.\n",
    "        for row in df.itertuples(index=False):\n",
    "            # print(row)\n",
    "            if row.State_name not in state_names_dict:\n",
    "                state_names_dict[row.State_name] = counter\n",
    "                # print(state_names_dict[row.State_name])\n",
    "                counter += 1\n",
    "        \n",
    "        df['Discretized_state_name'] = df['State_name'].map(state_names_dict)\n",
    "        df.to_csv(file_name, index=False)\n",
    "        print(\"SUCCESS: Discretized state names have been added to the provided CSV file.\")\n",
    "\n",
    "    else:\n",
    "        print(\"INFO: The CSV file provided already contains discretized state names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to test the function for yourself:\n",
    "# convert_state_names('csv_files/broken/pelican_without_dsn.csv')\n",
    "convert_state_names('csv_files/pelican.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "def is_csv_empty(file_name:str) -> None:\n",
    "    \"\"\"\n",
    "    This function checks if any value in each row is empty.\n",
    "    \n",
    "    :param file_name: The file name of the CSV file.\n",
    "    \"\"\"\n",
    "    with open(file_name, 'r') as csv_file:\n",
    "        # DictReader allows us to read each row of the CSV file as an ordered dictionary\n",
    "        csv_dict_reader = DictReader(csv_file)\n",
    "        empty_rows = []\n",
    "\n",
    "        # Iterate over each row\n",
    "        for count, row in enumerate(csv_dict_reader, start=2):\n",
    "            for value in row.values():\n",
    "                if not value:\n",
    "                    # If a value is empty in a given row, append the index of it\n",
    "                    empty_rows.append(count)\n",
    "                    break\n",
    "        \n",
    "        if not empty_rows:\n",
    "            print(\"INFO: The CSV file provided does not contain any empty values in its columns.\")\n",
    "\n",
    "        else:\n",
    "            raise CSVFileEmptyValues(empty_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to cause the exception to happen\n",
    "# is_csv_empty('csv_files/broken/blank.csv')\n",
    "is_csv_empty('csv_files/pelican.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_states_with_not_matching_transitions(file_name:str) -> None:\n",
    "    \"\"\"\n",
    "    This function checks if any state contains a not matching amount of transitions to its transition names or possible states to transition to.\n",
    "    \n",
    "    :param file_name: The file name of the CSV file.\n",
    "    \"\"\"\n",
    "    with open(file_name, 'r') as csv_file:\n",
    "      csv_dict_reader = DictReader(csv_file)\n",
    "      broken_states = []\n",
    "      broken_states_exist = False\n",
    "\n",
    "      for row in csv_dict_reader:\n",
    "\n",
    "        if len(row['Transitions_to_states'].split()) != int(row['Possible_discrete_actions_(transitions)']) or len(row['Transitions_to_states'].split()) != len(row['Transition_names'].split()) or int(row['Possible_discrete_actions_(transitions)']) != len(row['Transition_names'].split()):\n",
    "          if broken_states_exist == False:\n",
    "            broken_states_exist = True\n",
    "          broken_states.append(row['Unique_ID'])\n",
    "    \n",
    "    if broken_states_exist == False:\n",
    "      print(\"INFO: No states with a non-matching transition amount have been found.\")\n",
    "    else:\n",
    "      raise CSVFileTransitionsError(broken_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to cause the exception to happen\n",
    "# has_states_with_not_matching_transitions('csv_files/broken/pelican_broken_states.csv')\n",
    "has_states_with_not_matching_transitions('csv_files/pelican.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom gym environment framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSMEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pydot\n",
    "import random\n",
    "from csv import DictReader\n",
    "from IPython.display import Image, display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class FSMEnv(gym.Env):\n",
    "  \"\"\"\n",
    "  Custom environment that follows the OpenAI Gym interface.\n",
    "  \n",
    "  In this environment, an agent begins at a start state in a finite state machine and, by using provided transitions as its action space (which may vary), tries to learn the longest path from it without looping back to any previously visited state. \n",
    "  \n",
    "  All observations are directly provided from a CSV file, but as the CSV file might not fit into memory, any operations related to the file I/O are proceeded by traversing through the CSV file row by row. \n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, file_name:str, start_state_id:int=None, use_default_obs_space_limits:bool=False, max_row_count:int=1000):\n",
    "    \"\"\"\n",
    "    Creates and initializes the FSM gym environment.\n",
    "\n",
    "    :param file_name: The file name of the CSV file.\n",
    "    :param start_state_id: Allows to set a preset start state. If given a value of 0, the environment will randomize the chosen start state at each reset of the environment.\n",
    "    :param use_default_obs_space_limits: If false, the environment will try to scan and use the file for setting the maximum limits of the observation space. If true, the environment will use default observation space limits.\n",
    "    :param max_row_count: If not using default obs space limits, this parameter allows to use them anyway in case of hitting a preset row limit.\n",
    "    \"\"\"\n",
    "    super(FSMEnv, self).__init__()\n",
    "\n",
    "    self.file_name = file_name\n",
    "    self.start_state_id = start_state_id\n",
    "    self.use_default_obs_space_limits = use_default_obs_space_limits\n",
    "    self.max_row_count = max_row_count\n",
    "    self.randomize_start_state = False\n",
    "    self.start_states = []\n",
    "    self.start_state_has_been_set = False\n",
    "    \n",
    "    self.rendering_init = False\n",
    "\n",
    "    # When using a wrapper for vectorized environments, as we are \"stepping\" over, \n",
    "    # the environments in the venv reset automatically by themselves when an episode ends.\n",
    "\n",
    "    # This means we are not able to access the observation of an agent\n",
    "    # when the episode is already marked as \"done\", since the venv\n",
    "    # skips over right to the beginning of the episode.\n",
    "    \n",
    "    # The variable below therefore allows us to access the node that has been visited\n",
    "    # right before the reset in the rendering wrapper.\n",
    "    self.last_node_before_reset = None\n",
    "    preset_start_state = False\n",
    "\n",
    "    # We use the helper functions here to test the CSV file and essentially \n",
    "    # crash the initialization of the environment in case the CSV file is broken.\n",
    "    convert_state_names(file_name)\n",
    "    is_csv_empty(file_name)\n",
    "    has_states_with_not_matching_transitions(file_name)\n",
    "\n",
    "    # If no preset start state has been declared,\n",
    "    # the function will try to find such in the CSV file.\n",
    "    if start_state_id is None:\n",
    "      preset_start_state = False\n",
    "\n",
    "    # If the start state parameter has been set to 0,\n",
    "    # the function will try to find start states in the CSV file\n",
    "    # and randomize between them when resetting the environment.\n",
    "    elif int(start_state_id) == 0:\n",
    "      # Although we do have \"preset\" a start state (of 0), we set the boolean here to false\n",
    "      # to minimize the duplication of code in order to \n",
    "      # allow the function to append start states later on.\n",
    "      preset_start_state = False\n",
    "      self.randomize_start_state = True\n",
    "\n",
    "    # If a preset start state has been declared,\n",
    "    # the function will try to find it in the CSV file.\n",
    "    else:\n",
    "      preset_start_state = True\n",
    "      self.start_state_id = int(start_state_id)\n",
    "\n",
    "      with open(self.file_name, 'r') as csv_file:\n",
    "        correct_preset_start_state = False\n",
    "        # DictReader allows us to read each row of the CSV file as an ordered dictionary\n",
    "        csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "        # Iterate over each row. The row variable is a dict, representing a row in the CSV file\n",
    "        for row in csv_dict_reader:\n",
    "          if int(row['Unique_ID']) == self.start_state_id:\n",
    "            # If the row has been found, and is a start state, everything is correct.\n",
    "            if row['Start_state'] == '1':\n",
    "              correct_preset_start_state = True\n",
    "              self.start_state_has_been_set = True\n",
    "              # We break the loop as we don't need to traverse further through the file\n",
    "              break\n",
    "        \n",
    "        # If not, we raise an exception here\n",
    "        if correct_preset_start_state == False:\n",
    "          raise FSMIncorrectPresetStartStateError(self.start_state_id)\n",
    "\n",
    "    # The function will proceed to the following if statement if a preset start state has been not provided,\n",
    "    # in order to try to find any start states in the CSV file.\n",
    "    if preset_start_state == False:\n",
    "      any_start_state_found = False\n",
    "      multiple_start_states = False\n",
    "\n",
    "      with open(self.file_name, 'r') as csv_file:\n",
    "        csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "        for row in csv_dict_reader:\n",
    "          # Append each start state to a list in case the user decides \n",
    "          # further on to randomize the start state at each reset of the environment\n",
    "          if row['Start_state'] == '1':\n",
    "            self.start_states.append(int(row['Unique_ID']))\n",
    "            \n",
    "            if self.start_state_has_been_set == False:\n",
    "              # This boolean serves as a check to ensure there is\n",
    "              # at least one start state in the CSV file.\n",
    "              any_start_state_found = True\n",
    "              self.start_state_has_been_set = True\n",
    "              # In case there is only one start state, we set it as the default one.\n",
    "              self.start_state_id = int(row['Unique_ID'])\n",
    "\n",
    "            elif multiple_start_states == False:\n",
    "              self.start_state_id = None\n",
    "              multiple_start_states = True\n",
    "      \n",
    "        # If the user has not defined a preset start state or set the environment to\n",
    "        # randomize the start state each time, and multiple start states have been found,\n",
    "        # the function will ask the user to provide a start state to reset to each time, \n",
    "        # or if to set to randomize the start state.\n",
    "        if multiple_start_states == True and self.randomize_start_state == False:\n",
    "          print(\"Multiple start states have been found!\")\n",
    "          correct_start_state_provided = False\n",
    "\n",
    "          while correct_start_state_provided == False:\n",
    "            print(\"Please choose one of the found start states:\")\n",
    "            for unique_id in self.start_states:\n",
    "              print(unique_id)\n",
    "              \n",
    "            print(\"Or input 0 to randomize the start state at each reset of the environment.\")\n",
    "\n",
    "            self.start_state_id = int(input(\"Provide an unique ID: \"))\n",
    "            \n",
    "            if self.start_state_id not in self.start_states:\n",
    "              # If the user provided a value of 0, the env will randomize the start states.\n",
    "              if self.start_state_id == 0:\n",
    "                self.start_state_has_been_set = False\n",
    "                self.randomize_start_state = True\n",
    "                correct_start_state_provided = True\n",
    "              else:\n",
    "                print(\"ID provided is not in the list!\")\n",
    "            \n",
    "            else:\n",
    "              # If the user has provided a single start state, we empty the start_state list \n",
    "              # for memory conservation as we do not need to store them anymore.\n",
    "              self.start_states = []\n",
    "              correct_start_state_provided = True\n",
    "              self.start_state_has_been_set = True\n",
    "\n",
    "      # If no start states at all have been found, an exception is thrown\n",
    "      if any_start_state_found == False:\n",
    "        raise FSMStartStateNotFoundError()\n",
    "        \n",
    "    if self.randomize_start_state == True:\n",
    "      # Randomize a start state in case the user forgets to reset the env beforehand\n",
    "      self.start_state_id = random.choice(self.start_states)\n",
    "\n",
    "    if self.use_default_obs_space_limits == False:\n",
    "      row_counter = 0\n",
    "      self.max_amount_of_transitions = 0\n",
    "\n",
    "      # Scan the file for the total amount of states if not using default limit\n",
    "      with open(self.file_name, 'r') as csv_file:\n",
    "        csv_dict_reader = DictReader(csv_file)\n",
    "        for row in csv_dict_reader:\n",
    "          row_counter += 1\n",
    "\n",
    "          if int(row['Possible_discrete_actions_(transitions)']) > self.max_amount_of_transitions:\n",
    "            self.max_amount_of_transitions = int(row['Possible_discrete_actions_(transitions)'])\n",
    "\n",
    "          if row_counter >= self.max_row_count:\n",
    "            # If the amount of rows exceeds the max row count,\n",
    "            # default obs space limits will be used anyway\n",
    "            self.use_default_obs_space_limits = True\n",
    "            break\n",
    "      \n",
    "      if self.use_default_obs_space_limits == False:\n",
    "        self.obs_limit = row_counter\n",
    "      \n",
    "    if self.use_default_obs_space_limits == True:\n",
    "      # Set a limit here for the obs space\n",
    "      self.obs_limit = 100\n",
    "          \n",
    "    self.current_unique_id_state = self.start_state_id\n",
    "\n",
    "    # Define the action space\n",
    "    # In our case, we use a Discrete gym.spaces object\n",
    "    # When using an example action space of 2 discrete actions, we have two: 0 and 1 (0, n-1).\n",
    "    # Also set the initial transitions to states for the agent\n",
    "    with open(self.file_name, 'r') as csv_file:\n",
    "      csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "      for row in csv_dict_reader:\n",
    "        if int(row['Unique_ID']) == self.current_unique_id_state:\n",
    "          initial_actions = int(row['Possible_discrete_actions_(transitions)'])\n",
    "          self.action_space = gym.spaces.Discrete(initial_actions)\n",
    "          transitions_to_states = np.array(row['Transitions_to_states'].split(), dtype=np.int64)\n",
    "          self.current_discretized_state = int(row['Discretized_state_name'])\n",
    "          # We break the loop as we don't need to traverse further through the file\n",
    "          break\n",
    "\n",
    "    # Provide the agent with the discrete state names\n",
    "    # rather than the Unique IDs\n",
    "    discretized_transition_states = []\n",
    "\n",
    "    with open(self.file_name, 'r') as csv_file:\n",
    "      csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "      for row in csv_dict_reader:\n",
    "        for transition in transitions_to_states:\n",
    "          if transition == int(row['Unique_ID']):\n",
    "            discretized_transition_states.append(row['Discretized_state_name'])\n",
    "    \n",
    "    self.transitions_to_states = np.array(discretized_transition_states, dtype=np.int64)\n",
    "\n",
    "    # Use the amount of states in the file if False\n",
    "    if self.use_default_obs_space_limits == False:\n",
    "      # Due to the differing observation types (Discrete and Box),\n",
    "      # we use the Dict observation space to combine them together.\n",
    "      self.observation_space = gym.spaces.Dict(\n",
    "      {\n",
    "          # Unfortunately, SB3 does not support the np.uint64 variable type, which means \n",
    "          # that using high=np.inf with dtype=np.int64 would give us a negative value. \n",
    "          # This had to be worked around by using numpy to provide the maximum positive value that a dtype=np.int64 may have.\n",
    "\n",
    "          # Current discrete state obs\n",
    "          # +1 in the high bound to store n+1\n",
    "          'current_state': gym.spaces.Box(low=0, high=(self.obs_limit + 1), shape=(1,), dtype=np.int64),\n",
    "          # Past discrete states history obs\n",
    "          # +1 for the shape to account for a duplicate past state (when the agent goes to an already visited state [done status])\n",
    "          'past_states': gym.spaces.Box(low=0, high=np.iinfo(np.int64).max, shape=(self.obs_limit + 1,), dtype=np.int64),\n",
    "          # Available transitions to states obs\n",
    "          # Uses the max amount of transitions found in the file\n",
    "          'transitions_to_states': gym.spaces.Box(low=0, high=np.iinfo(np.int64).max, shape=(self.max_amount_of_transitions,), dtype=np.int64),\n",
    "          # Amount of states already visited\n",
    "          # Since we start at 0 after the env has had a reset,\n",
    "          # there's no need to add any value.\n",
    "          'amount_of_states_visited': gym.spaces.Box(low=0, high=self.obs_limit, shape=(1,), dtype=np.int64),\n",
    "      })\n",
    "\n",
    "      \"\"\"\n",
    "      Quick information on why the keys:\n",
    "      - 'current_state'\n",
    "      - 'amount_of_states_visited' \n",
    "      are not using a gym.spaces.Discrete space and use a Box space instead.\n",
    "\n",
    "      While a Discrete space would be way more fitting (since they are using a Discrete state space, duh),\n",
    "      from what I understand they create a combination with each other obs - meaning that we \n",
    "      straight-away run out of memory when using a giant Discrete space - 1,000,000,000 is enough to crash the env down.\n",
    "      gym.spaces.Discrete(np.iinfo(np.int32).max) is another example.\n",
    "\n",
    "      Although it does work with smaller state spaces, I think it's better to leave\n",
    "      the mechanism the same when working with smaller and larger state spaces.\n",
    "      In any case, I leave the Discrete keys here:\n",
    "\n",
    "      'current_state': gym.spaces.Discrete(self.obs_limit + 1),\n",
    "      'amount_of_states_visited': gym.spaces.Discrete(self.obs_limit),\n",
    "      \"\"\"\n",
    "\n",
    "      # These variables are initialized here in case of the user forgetting to use reset() before stepping through/predicting\n",
    "      self.transitions_to_states.resize(self.max_amount_of_transitions,)\n",
    "      self.past_discretized_states = np.zeros((self.obs_limit + 1,), dtype=np.int64)\n",
    "      self.past_unique_id_states = np.zeros((self.obs_limit + 1,), dtype=np.int64)\n",
    "\n",
    "    # Otherwise: \n",
    "    # Use np.int64 max for Box limits spaces\n",
    "    # Where needed, base on preset obs_limit for Box shape to save on memory\n",
    "    elif self.use_default_obs_space_limits == True:\n",
    "      self.observation_space = gym.spaces.Dict(\n",
    "      {\n",
    "          # Current discrete state obs\n",
    "          'current_state': gym.spaces.Box(low=0, high=np.iinfo(np.int64).max, shape=(1,), dtype=np.int64),\n",
    "          # Past discrete states history obs\n",
    "          'past_states': gym.spaces.Box(low=0, high=np.iinfo(np.int64).max, shape=(self.obs_limit,), dtype=np.int64),\n",
    "          # Available transitions to states obs\n",
    "          'transitions_to_states': gym.spaces.Box(low=0, high=np.iinfo(np.int64).max, shape=(self.obs_limit,), dtype=np.int64),\n",
    "          # Amount of states already visited\n",
    "          'amount_of_states_visited': gym.spaces.Box(low=0, high=np.iinfo(np.int64).max, shape=(1,), dtype=np.int64),\n",
    "      })\n",
    "\n",
    "      self.transitions_to_states.resize((self.obs_limit,))\n",
    "      self.past_discretized_states = np.zeros((self.obs_limit,), dtype=np.int64)\n",
    "      self.past_unique_id_states = np.zeros((self.obs_limit,), dtype=np.int64)\n",
    "\n",
    "    # This observation also serves as a counter for the two past_states arrays\n",
    "    self.amount_of_states_visited = 0\n",
    "    self.last_node_before_reset = None\n",
    "\n",
    "    print(\"INFO: Environment successfully initialized.\")\n",
    "    print(\"Initial action space:\", self.action_space)\n",
    "    print(\"Observation space:\")\n",
    "    print(\"- High bound of 'current_state' key: {}\".format(self.observation_space['current_state'].high))\n",
    "    print(\"- Shape of 'past_states' key: {}\".format(self.observation_space['past_states'].shape))\n",
    "    print(\"- Shape of 'transitions_to_states' key: {}\".format(self.observation_space['transitions_to_states'].shape))\n",
    "    print(\"- High bound of 'amount_of_states_visited' key: {}\".format(self.observation_space['amount_of_states_visited'].high))\n",
    "    # print(\"Total amount of states in the CSV file: {}\".format(self.row_counter))\n",
    "    # No longer working :P\n",
    "\n",
    "  def reset(self) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Resets the environment.\n",
    "    :return: (np.ndarray)\n",
    "    \"\"\"\n",
    "    # Initialize the agent at the start state\n",
    "    if self.use_default_obs_space_limits == False:\n",
    "      # +1 for the shape to account for a duplicate past state (when the agent goes to an already visited state [done status])\n",
    "      self.past_discretized_states = np.zeros((self.obs_limit + 1,), dtype=np.int64)\n",
    "      self.past_unique_id_states = np.zeros((self.obs_limit + 1,), dtype=np.int64)\n",
    "    else:\n",
    "      self.past_discretized_states = np.zeros((self.obs_limit,), dtype=np.int64)\n",
    "      self.past_unique_id_states = np.zeros((self.obs_limit,), dtype=np.int64)\n",
    "\n",
    "    # Counter for the past 2 arrays as well.\n",
    "    # Leaving it at 0 will be a bit untrue since \n",
    "    # we have visited the starting state, but it will be better for the reward.\n",
    "    self.amount_of_states_visited = 0\n",
    "\n",
    "    if self.randomize_start_state == True:\n",
    "      self.start_state_id = random.choice(self.start_states)\n",
    "      # print(\"I am choosing random!\", self.start_state_id)\n",
    "    \n",
    "    self.current_unique_id_state = self.start_state_id\n",
    "\n",
    "    with open(self.file_name, 'r') as csv_file:\n",
    "      csv_dict_reader = DictReader(csv_file)\n",
    "      \n",
    "      for row in csv_dict_reader:\n",
    "        if self.start_state_id == int(row['Unique_ID']):\n",
    "          self.current_discretized_state = int(row['Discretized_state_name'])\n",
    "          transitions_to_states = np.array(row['Transitions_to_states'].split(), dtype=np.int64)\n",
    "\n",
    "          self.past_discretized_states[self.amount_of_states_visited] = int(row['Discretized_state_name'])\n",
    "          self.past_unique_id_states[self.amount_of_states_visited] = int(row['Unique_ID'])\n",
    "          # We break the loop as we don't need to traverse further through the file\n",
    "          break\n",
    "\n",
    "    # Provide the agent with the discrete state names\n",
    "    # rather than the Unique IDs\n",
    "    discretized_transition_states = []\n",
    "\n",
    "    with open(self.file_name, 'r') as csv_file:\n",
    "      csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "      for row in csv_dict_reader:\n",
    "        for transition in transitions_to_states:\n",
    "          if transition == int(row['Unique_ID']):\n",
    "            discretized_transition_states.append(row['Discretized_state_name'])\n",
    "    \n",
    "    self.transitions_to_states = np.array(discretized_transition_states, dtype=np.int64)\n",
    "\n",
    "    if self.use_default_obs_space_limits == False:\n",
    "      self.transitions_to_states.resize(self.max_amount_of_transitions,)\n",
    "    else:\n",
    "      self.transitions_to_states.resize(self.obs_limit,)\n",
    "\n",
    "    observation = {\n",
    "      # We need to convert the integers to a numpy array for tensor flattening\n",
    "      'current_state': np.array([self.current_discretized_state], dtype=np.int64),\n",
    "      'past_states': self.past_discretized_states,\n",
    "      'transitions_to_states': self.transitions_to_states,\n",
    "      'amount_of_states_visited': np.array([self.amount_of_states_visited], dtype=np.int64), \n",
    "    }\n",
    "\n",
    "    return observation\n",
    "\n",
    "  def step(self, action:int):\n",
    "    \"\"\"\n",
    "    Steps over the environment with the chosen action.\n",
    "    :param action: Action (number).\n",
    "    \"\"\"\n",
    "    with open(self.file_name, 'r') as csv_file:\n",
    "      csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "      for row in csv_dict_reader:\n",
    "        if int(row['Discretized_state_name']) == self.current_discretized_state:\n",
    "          # The line below splits the string into a list that \n",
    "          # contains the unique IDs of states that are possible to transition to\n",
    "          # from the current state, and uses the action integer \n",
    "          # to choose a transition from the list.\n",
    "          # The int() function just converts the string to an integer.\n",
    "          self.current_unique_id_state = int(row['Transitions_to_states'].split()[action])\n",
    "          break\n",
    "      \n",
    "      new_state_successfully_found = False\n",
    "\n",
    "    with open(self.file_name, 'r') as csv_file:\n",
    "      csv_dict_reader = DictReader(csv_file)\n",
    "      \n",
    "      for row in csv_dict_reader:\n",
    "        if int(row['Unique_ID']) == self.current_unique_id_state:\n",
    "          new_state_successfully_found = True\n",
    "          self.current_discretized_state = int(row['Discretized_state_name'])\n",
    "          transitions_to_states = np.array(row['Transitions_to_states'].split(), dtype=np.int64)\n",
    "          actions = int(row['Possible_discrete_actions_(transitions)'])\n",
    "          print(actions)\n",
    "          self.action_space = gym.spaces.Discrete(actions)\n",
    "          break\n",
    "    \n",
    "    if new_state_successfully_found == True:\n",
    "      # Provide the agent with the discrete state names\n",
    "      # rather than the Unique IDs\n",
    "      discretized_transition_states = []\n",
    "\n",
    "      with open(self.file_name, 'r') as csv_file:\n",
    "        csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "        for row in csv_dict_reader:\n",
    "          for transition in transitions_to_states:\n",
    "            if transition == int(row['Unique_ID']):\n",
    "              discretized_transition_states.append(row['Discretized_state_name'])\n",
    "      \n",
    "      self.transitions_to_states = np.array(discretized_transition_states, dtype=np.int64)\n",
    "\n",
    "      if self.use_default_obs_space_limits == False:\n",
    "        # Resize the obs for the defined observation space\n",
    "        self.transitions_to_states.resize(self.max_amount_of_transitions,)\n",
    "      else:\n",
    "        self.transitions_to_states.resize(self.obs_limit,)\n",
    "\n",
    "      # print(\"Transitions to states when stepping:\", self.transitions_to_states)\n",
    "      \n",
    "      self.amount_of_states_visited += 1\n",
    "\n",
    "      if self.current_unique_id_state in self.past_unique_id_states:\n",
    "        # If we already have been in the current state, the episode is done.\n",
    "        # We store the last node for the rendering wrapper usage\n",
    "        self.last_node_before_reset = self.current_unique_id_state\n",
    "        reward = 0\n",
    "        done = True\n",
    "        # print(self.past_unique_id_states)\n",
    "        # print(self.start_state_id)\n",
    "\n",
    "      else:\n",
    "        self.last_node_before_reset = None\n",
    "        reward = self.amount_of_states_visited\n",
    "        done = False\n",
    "\n",
    "      # If we are using the default obs space limits and are hitting the max limits of the observation space,\n",
    "      # we slice the arrays to remove obsolete states.\n",
    "      if self.use_default_obs_space_limits == True and self.amount_of_states_visited == (self.obs_limit - 1):\n",
    "        self.past_discretized_states = self.past_discretized_states[1:]\n",
    "        self.past_unique_id_states = self.past_unique_id_states[1:]\n",
    "        # Append the new state\n",
    "        np.append(self.past_discretized_states, self.current_discretized_state)\n",
    "        np.append(self.past_unique_id_states, self.current_unique_id_state)\n",
    "\n",
    "      else:\n",
    "        # Else we just change the zeroes in the arrays to the state \"value\"\n",
    "        self.past_discretized_states[self.amount_of_states_visited] = self.current_discretized_state\n",
    "        self.past_unique_id_states[self.amount_of_states_visited] = self.current_unique_id_state\n",
    "        \n",
    "    elif new_state_successfully_found == False:\n",
    "      raise FSMTransitionStateNotFoundError(self.current_unique_id_state)\n",
    "\n",
    "    info = {}\n",
    "\n",
    "    observation = {\n",
    "      'current_state': np.array([self.current_discretized_state], dtype=np.int64),\n",
    "      'past_states': self.past_discretized_states,\n",
    "      'transitions_to_states': self.transitions_to_states,\n",
    "      'amount_of_states_visited': np.array([self.amount_of_states_visited], dtype=np.int64),\n",
    "    }\n",
    "\n",
    "    # print(\"Current ID: {} Action taken: {} Is done: {} Reward: {} Action space: {} Past states: {}\".format(self.current_unique_id_state, action, done, reward, self.action_space, self.past_discretized_states))\n",
    "\n",
    "    return observation, reward, done, info\n",
    "\n",
    "  def render(self, action, done:bool, mode='visual'):\n",
    "    \"\"\"\n",
    "    Renders the prediction of the model by drawing the nodes and taken transitions.\n",
    "    Needs to render after env.reset() for proper functioning, otherwise it does not have the previous node stored.\n",
    "\n",
    "    :param mode: Rendering mode - only visual is supported.\n",
    "    :param action: Action taken.\n",
    "    :param done: Whether the environment is done.\n",
    "    \"\"\"\n",
    "    if mode == 'visual':\n",
    "      if self.rendering_init == False:\n",
    "        # Initialize the graph, as otherwise it would be overwritten with each call of render()\n",
    "        self.rendering_init = True\n",
    "        self.rendering_graph = pydot.Dot(graph_type='digraph', strict=True)\n",
    "      \n",
    "      if not done:\n",
    "        if self.amount_of_states_visited == 0 and action == None:\n",
    "          # We're at the start state\n",
    "          # Store the start state as the previous node\n",
    "          # Add the start state as a node\n",
    "          with open(self.file_name, 'r') as csv_file:\n",
    "            csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "            for row in csv_dict_reader:\n",
    "              if int(row['Unique_ID']) == self.start_state_id:\n",
    "                original_name = row['State_name']\n",
    "                start_state_name = original_name + \" \" + \"[START STATE]\"\n",
    "\n",
    "                self.rendering_graph.add_node(pydot.Node(name=self.start_state_id, label=start_state_name, style=\"filled\", fillcolor=\"white\", fontname=\"Impact\", fontsize='32'))\n",
    "                self.rendering_previous_node = self.start_state_id\n",
    "\n",
    "        else:\n",
    "            # We're going through the graph\n",
    "            # Store the new node\n",
    "            # Add a transition between the previous node and current one\n",
    "            with open(self.file_name, 'r') as csv_file:\n",
    "              csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "              for row in csv_dict_reader:\n",
    "                if int(row['Unique_ID']) == self.rendering_previous_node:\n",
    "                  transition_name = row['Transition_names'].split()[action]\n",
    "                if int(row['Unique_ID']) == self.current_unique_id_state:\n",
    "                  original_name = row['State_name']\n",
    "\n",
    "            self.rendering_graph.add_node(pydot.Node(name=self.current_unique_id_state, label=original_name, style=\"filled\", fillcolor=\"white\", fontname=\"Impact\", fontsize=\"32\"))\n",
    "            self.rendering_graph.add_edge(pydot.Edge(self.rendering_previous_node, self.current_unique_id_state, label=transition_name, color=\"blue\", fontname=\"Arial\", fontsize=\"32\"))\n",
    "            self.rendering_previous_node = self.current_unique_id_state\n",
    "\n",
    "      elif done:\n",
    "        # The episode is done and the venv will reset automatically\n",
    "        # Add the transition between the previous and last node before reset\n",
    "        # We're using self.last_node_before_reset, as self.current_unique_id_state would\n",
    "        # provide us the start state id due to the reset of the env\n",
    "        with open(self.file_name, 'r') as csv_file:\n",
    "          csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "          for row in csv_dict_reader:\n",
    "            if int(row['Unique_ID']) == self.rendering_previous_node:\n",
    "              transition_name = row['Transition_names'].split()[action]\n",
    "        \n",
    "        self.rendering_graph.add_edge(pydot.Edge(self.rendering_previous_node, self.last_node_before_reset, label=transition_name, color='blue', fontname=\"Arial\", fontsize='32'))\n",
    "      \n",
    "      clear_output(wait=True)\n",
    "      plt = Image(self.rendering_graph.create_png())\n",
    "      display(plt)\n",
    "\n",
    "    else:\n",
    "      raise NotImplementedError()\n",
    "\n",
    "  def close(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the SB3 check_env function\n",
    "This allows us to see whether the environment has been defined correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env = FSMEnv('csv_files/pelican.csv', start_state_id=0, use_default_obs_space_limits=True)\n",
    "# If the environment doesn't follow the interface, an error will be thrown.\n",
    "# Otherwise, everything is good!\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling actions and stepping through the env\n",
    "Testing if the env steps through correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FSMEnv('csv_files/pelican.csv', start_state_id=1, use_default_obs_space_limits=False)\n",
    "env.reset()\n",
    "print(\"######################\")\n",
    "print(\"Action sampling test: \")\n",
    "for i in range(5):\n",
    "    obs, reward, done, info = env.step(env.action_space.sample()) # Sample a random action and step\n",
    "    print(\"Reward:\", reward, \"Done?:\", done, \"Observation\", obs)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized environment wrapper for rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSMWrapperError(Exception):\n",
    "    \"\"\"\n",
    "    Throws an exception in case the rendering wrapper is not used with SubprocVecEnv (one agent per env [multithreading]),\n",
    "    but rather with DummyVecEnv (multiple agents per env), which is not supported due to I/O issues.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        print(\"ERROR: This wrapper only works with SubprocVecEnvs due to\")\n",
    "        print(\"learning and rendering errors while running multiple environments on the same process.\")\n",
    "        print(\"Please use the create_vec_fsm_env() function to create the vectorized environment and wrap it if needed,\")\n",
    "        print(\"or, in case of wanting to use the make_vec_env() helper function from SB3,\")\n",
    "        print(\"please set the vec_env_cls parameter to SubprocVecEnv (vec_env_cls=SubprocVecEnv).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "from IPython.display import Image, display\n",
    "from IPython.display import clear_output\n",
    "from stable_baselines3.common.vec_env.base_vec_env import VecEnv, VecEnvStepReturn, VecEnvWrapper\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "class FSMRenderingWrapper(VecEnvWrapper):\n",
    "    \"\"\"\n",
    "    A vectorized wrapper for monitoring (usually) multiple environments\n",
    "    and rendering a graph from their observations.\n",
    "\n",
    "    More information on vectorized environments:\n",
    "        https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html\n",
    "\n",
    "    :param venv: The vectorized environment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, venv: VecEnv):\n",
    "        \"\"\"\n",
    "        Creates a rendering vectorized wrapper.\n",
    "\n",
    "        :param venv: The vectorized environment.\n",
    "        \"\"\"\n",
    "        if type(venv) is not SubprocVecEnv:\n",
    "            raise FSMWrapperError()\n",
    "\n",
    "        super(FSMRenderingWrapper, self).__init__(venv=venv, observation_space=venv.observation_space)\n",
    "\n",
    "        # Graph initialization.\n",
    "        # The strict parameter ensures no edge or node is drawn twice\n",
    "        self.rendering_graph = pydot.Dot(graph_type='digraph', strict=True)\n",
    "        # This dict stores the amount of visits to nodes\n",
    "        self.rendering_heatmap_dict = {}\n",
    "        self.num_timesteps = 0\n",
    "        self.total_amount_of_visits = 0\n",
    "\n",
    "        self.num_envs = venv.num_envs\n",
    "        # How often will the graph be rendered and drawn (i.e. num_envs=8 * 3000 = per 24000 timesteps)\n",
    "        self.rendering_modulo = self.num_envs * 3000\n",
    "\n",
    "        # The following get_attr function takes the attribute from first environment,\n",
    "        # however it still gets returned as a list: \n",
    "        # therefore, it is required to use an index to get the value we need.\n",
    "        # We take the index of 0 as each env has the same init attributes, \n",
    "        # and there is always at least one environment running.\n",
    "        self.file_name = self.venv.get_attr('file_name', 0)[0]\n",
    "        start_state_has_been_set = self.venv.get_attr('start_state_has_been_set', 0)[0]\n",
    "        preset_start_state = self.venv.get_attr('start_state_id', 0)[0]\n",
    "        start_states = self.venv.get_attr('start_states', 0)[0]\n",
    "        randomize_start_state = self.venv.get_attr('randomize_start_state', 0)[0]\n",
    "\n",
    "        # If the env randomizes start states,\n",
    "        # we can already add all of the start states nodes to the dict\n",
    "        if randomize_start_state == True:\n",
    "            for start_state_id in start_states:\n",
    "                self.rendering_heatmap_dict[start_state_id] = 0\n",
    "        \n",
    "        elif start_state_has_been_set == True:\n",
    "            self.rendering_heatmap_dict[preset_start_state] = 0\n",
    "\n",
    "        with open(self.file_name, 'r') as csv_file:\n",
    "            csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "            for row in csv_dict_reader:\n",
    "                if randomize_start_state == True:\n",
    "                    for start_state_id in start_states:\n",
    "                        if int(row['Unique_ID']) == start_state_id:\n",
    "                            original_name = row['State_name']\n",
    "                            start_state_name = original_name + \" \" + \"[START STATE]\"\n",
    "\n",
    "                            self.rendering_graph.add_node(pydot.Node(name=start_state_id, label=start_state_name, style='filled', fillcolor='white', fontname='Impact', fontsize='32'))\n",
    "\n",
    "                elif start_state_has_been_set == True:\n",
    "                    if int(row['Unique_ID']) == preset_start_state:\n",
    "                        original_name = row['State_name']\n",
    "                        start_state_name = original_name + \" \" + \"[START STATE]\"\n",
    "\n",
    "                        self.rendering_graph.add_node(pydot.Node(name=preset_start_state, label=start_state_name, style='filled', fillcolor='white', fontname='Impact', fontsize='32'))\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.venv.reset()\n",
    "        return obs\n",
    "\n",
    "    def step_async(self, actions: np.ndarray) -> None:\n",
    "        self.actions = actions\n",
    "        self.previous_nodes = self.venv.get_attr('current_unique_id_state')\n",
    "        self.venv.step_async(actions)\n",
    "\n",
    "    def step_wait(self) -> VecEnvStepReturn:\n",
    "        obs, reward, done, info = self.venv.step_wait()\n",
    "        \n",
    "        # print(\"Past history of states: \", self.venv.get_attr('past_unique_id_states', 0)[0])\n",
    "\n",
    "        current_nodes = self.venv.get_attr('current_unique_id_state')\n",
    "        new_nodes_found = []\n",
    "\n",
    "        last_nodes_before_reset = self.venv.get_attr('last_node_before_reset')\n",
    "\n",
    "        # print(self.rendering_heatmap_dict)\n",
    "\n",
    "        # VecEnv resets automatically when encountering the done signal\n",
    "        # This means that environments that are done will reset\n",
    "        # between the step_async() and step_wait() function\n",
    "        # Therefore, we have to account for when an env is done and when it is not in our rendering\n",
    "        \n",
    "        # In theory, VecEnv provides a terminal_observation key in their info dict,\n",
    "        # however since we need the self.last_node_before_reset for the env.render() function anyway\n",
    "        # (which does not have access to the venv via itself), we're just going to use that instead of\n",
    "        # unpacking the dict\n",
    "        for current_node, is_done, last_node_before_reset in zip(current_nodes, done, last_nodes_before_reset):\n",
    "            if is_done == True:\n",
    "                self.rendering_heatmap_dict[last_node_before_reset] += 1\n",
    "                self.total_amount_of_visits += 1\n",
    "                new_nodes_found.append(False)\n",
    "            else:\n",
    "                if current_node not in self.rendering_heatmap_dict:\n",
    "                    self.rendering_heatmap_dict[current_node] = 1\n",
    "                    self.total_amount_of_visits += 1\n",
    "                    new_nodes_found.append(True)\n",
    "                else:\n",
    "                    # If already in the heatmap dict, just add 1\n",
    "                    self.rendering_heatmap_dict[current_node] += 1\n",
    "                    self.total_amount_of_visits += 1\n",
    "                    new_nodes_found.append(False)\n",
    "        \n",
    "        # print(\"Previous nodes:\", self.previous_nodes)\n",
    "        # print(\"Current nodes:\", current_nodes)\n",
    "        # print(\"New nodes found?:\", new_nodes_found)\n",
    "\n",
    "        transition_names = []\n",
    "\n",
    "        for action, previous_node, current_node, new_node_found in zip(self.actions, self.previous_nodes, current_nodes, new_nodes_found):\n",
    "            with open(self.file_name, 'r') as csv_file:\n",
    "                # pass the file object to DictReader() to get the DictReader object\n",
    "                csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "                # iterate over each line as a ordered dictionary\n",
    "                for row in csv_dict_reader:\n",
    "\n",
    "                    if int(row['Unique_ID']) == previous_node:\n",
    "                        transition_name = row['Transition_names'].split()[action]\n",
    "                        transition_names.append(transition_name)\n",
    "                    \n",
    "                    if new_node_found == True:\n",
    "                        # row variable is a dictionary that represents a row in csv\n",
    "                        if int(row['Unique_ID']) == current_node:\n",
    "                            original_name = row['State_name']\n",
    "                            # print(\"Original name:\", original_name)\n",
    "\n",
    "            if new_node_found == True:\n",
    "                self.rendering_graph.add_node(pydot.Node(name=current_node, label=original_name, style=\"filled\", fillcolor=\"white\", fontname=\"Impact\", fontsize='32'))\n",
    "                # print(action, previous_node, current_node, new_node_found, transition_name, original_name)\n",
    "\n",
    "        # VecEnv resets automatically when encountering the done signal\n",
    "        # This means that environments that are done will reset\n",
    "        # between the step_async() and step_wait() function\n",
    "        # Therefore, we have to account for when an env is done and when it is not in our rendering\n",
    "        \n",
    "        # In theory, VecEnv provides a terminal_observation key in their info dict,\n",
    "        # however since we need the self.last_node_before_reset for the env.render() function anyway\n",
    "        # (which does not have access to the venv via itself), we're just going to use that instead of\n",
    "        # unpacking the dict\n",
    "        for previous_node, current_node, transition_name, is_done, last_node_before_reset in zip(self.previous_nodes, current_nodes, transition_names, done, last_nodes_before_reset):\n",
    "            if is_done == True:\n",
    "                self.rendering_graph.add_edge(pydot.Edge(previous_node, last_node_before_reset, label=transition_name, color='blue', fontname=\"Arial\", fontsize='32'))\n",
    "            else:\n",
    "                self.rendering_graph.add_edge(pydot.Edge(previous_node, current_node, label=transition_name, color='blue', fontname=\"Arial\", fontsize='32'))\n",
    "        \n",
    "        self.num_timesteps += self.num_envs\n",
    "\n",
    "        if self.num_timesteps % self.rendering_modulo == 0:\n",
    "            local_max = 0\n",
    "            for node in self.rendering_graph.get_nodes():\n",
    "                if self.rendering_heatmap_dict[int(node.get_name())] > local_max:\n",
    "                    local_max = self.rendering_heatmap_dict[int(node.get_name())]\n",
    "                \n",
    "            for node in self.rendering_graph.get_nodes():\n",
    "                amount_of_visits = self.rendering_heatmap_dict[int(node.get_name())]\n",
    "                # Convert the range from 0.0 - local_max to 1.0 - 0.0 for heatmap colouring\n",
    "                # NewValue = (((OldValue - OldMin) * (NewMax - NewMin)) / (OldMax - OldMin)) + NewMin\n",
    "                # Simple linear mapping\n",
    "                # The formula below has had the zeros removed for efficiency\n",
    "                new_hsv_value = (-amount_of_visits / local_max) + 1.0\n",
    "                node.set_fillcolor(\"0.0 0.0 {}\".format(new_hsv_value))\n",
    "                \n",
    "                # If the brightness is equal or below to 0.5, we change the font color to white\n",
    "                if new_hsv_value <= 0.5:\n",
    "                    node.set_fontcolor(\"white\")\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            plt = Image(self.rendering_graph.create_png())\n",
    "            display(plt)\n",
    "\n",
    "            # sum_of_visits = 0\n",
    "            # Loop below uses the keys and values from the heatmap dict\n",
    "            # to print the original state names and the amount of visits to each\n",
    "            for key, value in self.rendering_heatmap_dict.items():\n",
    "                with open(self.file_name, 'r') as csv_file:\n",
    "                    csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "                    for row in csv_dict_reader:\n",
    "                        if int(row['Unique_ID']) == key:\n",
    "                        # print(\"Unique ID in row:\", row['Unique_ID'], \"Self.env.current_unique_id_state:\", self.env.current_unique_id_state)\n",
    "                            original_name = row['State_name']\n",
    "                print(original_name, value)\n",
    "                # sum_of_visits += value\n",
    "            # print(\"Total:\", sum_of_visits)\n",
    "            print(\"Total:\", self.num_timesteps)\n",
    "\n",
    "        return obs, reward, done, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function for easy creation of a wrapped venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "def create_vec_fsm_env(file_name:str, num_envs:int, start_state_id:int=0, use_default_obs_space_limits:bool=False, max_row_count:int=1000, wrapped:bool=True):\n",
    "    \"\"\"\n",
    "    Creates a vectorized FSM environment in one line, wrapped if needed. \n",
    "\n",
    "    :param file_name: The file name of the CSV file.\n",
    "    :param num_envs: The amount of environments running at the same time. WARNING: Setting an amount above the amount of logical cores will result in a slowdown.\n",
    "    :param start_state_id: Allows to set a preset start state. If given a value of 0, the environments will randomize the chosen start state at each reset of the environment.\n",
    "    :param use_default_obs_space_limits: If false, the environments will try to scan and use the file for setting the maximum limits of the observation space. If true, the environments will use default observation space limits.\n",
    "    :param max_row_count: If not using default obs space limits, this parameter allows to use them anyway in case of hitting a preset row limit.\n",
    "    :param wrapped: Whether to use a rendering wrapper.\n",
    "    \"\"\"\n",
    "    env = FSMEnv(file_name, start_state_id, use_default_obs_space_limits, max_row_count)\n",
    "    env = make_vec_env(lambda: env, n_envs=num_envs, vec_env_cls=SubprocVecEnv)\n",
    "\n",
    "    if wrapped == True:\n",
    "        env = FSMRenderingWrapper(env)\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and learning on environments:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variables for controlling multiple learning commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_NUM_TIMESTEPS = 500000\n",
    "GLOBAL_GAMMA = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pelican FSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('original_graphs/pelican.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on the env with supported algorithms\n",
    "Multiprocessing and discrete actions are only available with the use of A2C and PPO in the SB3 package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, A2C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with wrapper to render the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_vec_fsm_env('csv_files/pelican.csv', num_envs=8, start_state_id=0, wrapped=True)\n",
    "\n",
    "model = A2C('MultiInputPolicy', env, gamma=GLOBAL_GAMMA, verbose=0).learn(GLOBAL_NUM_TIMESTEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with EvalCallback to save best model and access logs for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "env = create_vec_fsm_env('csv_files/pelican.csv', num_envs=8, start_state_id=0, wrapped=False)\n",
    "eval_env = create_vec_fsm_env('csv_files/pelican.csv', num_envs=1, start_state_id=0, wrapped=False)\n",
    "\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path='./saved_models/pelican/A2C/',\n",
    "                             eval_freq=500, deterministic=True, render=False)\n",
    "\n",
    "model = A2C('MultiInputPolicy', env, gamma=GLOBAL_GAMMA, verbose=0, tensorboard_log=\"./training_logs/pelican/\").learn(GLOBAL_NUM_TIMESTEPS, tb_log_name=\"A2C\", callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with wrapper to render the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_vec_fsm_env('csv_files/pelican.csv', num_envs=8, start_state_id=0, wrapped=True)\n",
    "\n",
    "model = PPO('MultiInputPolicy', env, gamma=GLOBAL_GAMMA, verbose=0).learn(GLOBAL_NUM_TIMESTEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with EvalCallback to save best model and access logs for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_vec_fsm_env('csv_files/pelican.csv', num_envs=8, start_state_id=0, wrapped=False)\n",
    "eval_env = create_vec_fsm_env('csv_files/pelican.csv', num_envs=1, start_state_id=0, wrapped=False)\n",
    "\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path='./saved_models/pelican/PPO/',\n",
    "                             eval_freq=500, deterministic=True, render=False)\n",
    "\n",
    "model = PPO('MultiInputPolicy', env, gamma=GLOBAL_GAMMA, verbose=0, tensorboard_log=\"./training_logs/pelican/\").learn(GLOBAL_NUM_TIMESTEPS, tb_log_name=\"PPO\", callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO and A2C performance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toaster FSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('original_graphs/toaster.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on the env with supported algorithms\n",
    "Multiprocessing and discrete actions are only available with the use of A2C and PPO in the SB3 package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with wrapper to render the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_vec_fsm_env('csv_files/toaster.csv', num_envs=8, start_state_id=0, wrapped=False)\n",
    "\n",
    "model = A2C('MultiInputPolicy', env, gamma=GLOBAL_GAMMA, verbose=1).learn(GLOBAL_NUM_TIMESTEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with EvalCallback to save best model and access logs for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "env = create_vec_fsm_env('csv_files/toaster.csv', num_envs=8, start_state_id=0, wrapped=False)\n",
    "eval_env = create_vec_fsm_env('csv_files/toaster.csv', num_envs=1, start_state_id=0, wrapped=False)\n",
    "\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path='./saved_models/toaster/A2C/',\n",
    "                             eval_freq=500, deterministic=True, render=False)\n",
    "\n",
    "model = A2C('MultiInputPolicy', env, gamma=GLOBAL_GAMMA, verbose=0, tensorboard_log=\"./training_logs/toaster/\").learn(GLOBAL_NUM_TIMESTEPS, tb_log_name=\"A2C\", callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with wrapper to render the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_vec_fsm_env('csv_files/toaster.csv', num_envs=8, start_state_id=0, wrapped=True)\n",
    "\n",
    "model = PPO('MultiInputPolicy', env, gamma=GLOBAL_GAMMA, verbose=0).learn(GLOBAL_NUM_TIMESTEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with EvalCallback to save best model and access logs for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_vec_fsm_env('csv_files/toaster.csv', num_envs=8, start_state_id=0, wrapped=False)\n",
    "eval_env = create_vec_fsm_env('csv_files/toaster.csv', num_envs=1, start_state_id=0, wrapped=False)\n",
    "\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path='./saved_models/toaster/PPO/',\n",
    "                             eval_freq=500, deterministic=True, render=False)\n",
    "\n",
    "model = PPO('MultiInputPolicy', env, gamma=GLOBAL_GAMMA, verbose=0, tensorboard_log=\"./tensorboard_logs/toaster/\").learn(GLOBAL_NUM_TIMESTEPS, tb_log_name=\"PPO\", callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO and A2C performance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maze FSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agent cannot return on his path\n",
    "- Can hit into walls\n",
    "- Varying action space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs of the maze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on the env with supported algorithms\n",
    "Multiprocessing and discrete actions are only available with the use of A2C and PPO in the SB3 package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with wrapper to render the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_vec_fsm_env('csv_files/maze.csv', num_envs=8, start_state_id=0, wrapped=True)\n",
    "\n",
    "model = A2C('MultiInputPolicy', env, gamma=GLOBAL_GAMMA, verbose=0).learn(GLOBAL_NUM_TIMESTEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with EvalCallback to save best model and access logs for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "env = create_vec_fsm_env('csv_files/maze.csv', num_envs=8, start_state_id=0, wrapped=False)\n",
    "eval_env = create_vec_fsm_env('csv_files/maze.csv', num_envs=1, start_state_id=0, wrapped=False)\n",
    "\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path='./saved_models/toaster/A2C/',\n",
    "                             eval_freq=500, deterministic=True, render=False)\n",
    "\n",
    "model = A2C('MultiInputPolicy', env, gamma=GLOBAL_GAMMA, verbose=0, tensorboard_log=\"./training_logs/toaster/\").learn(GLOBAL_NUM_TIMESTEPS, tb_log_name=\"A2C\", callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with wrapper to render the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_vec_fsm_env('csv_files/maze.csv', num_envs=8, start_state_id=0, wrapped=True)\n",
    "\n",
    "model = PPO('MultiInputPolicy', env, gamma=GLOBAL_GAMMA, verbose=0).learn(GLOBAL_NUM_TIMESTEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with EvalCallback to save best model and access logs for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = create_vec_fsm_env('csv_files/toaster.csv', num_envs=8, start_state_id=0, wrapped=False)\n",
    "eval_env = create_vec_fsm_env('csv_files/toaster.csv', num_envs=1, start_state_id=0, wrapped=False)\n",
    "\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path='./saved_models/toaster/PPO/',\n",
    "                             eval_freq=500, deterministic=True, render=False)\n",
    "\n",
    "model = PPO('MultiInputPolicy', env, gamma=GLOBAL_GAMMA, verbose=0, tensorboard_log=\"./tensorboard_logs/toaster/\").learn(GLOBAL_NUM_TIMESTEPS, tb_log_name=\"PPO\", callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO and A2C performance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maze distance graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('original_graphs/maze_distance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maze discrete states graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('original_graphs/maze_discrete.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maze unique IDs graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('original_graphs/maze_unique_ids.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's left:\n",
    "- Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "from IPython.display import Image, display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Render here\n",
    "class FSMRenderingEnvWrapper(gym.Wrapper):\n",
    "  \"\"\"\n",
    "  :param env: (gym.Env) Gym environment that will be wrapped\n",
    "  \"\"\"\n",
    "  def __init__(self, env: gym.Env):\n",
    "\n",
    "    # Initialize the graph here\n",
    "    self.rendering_graph = pydot.Dot(graph_type='digraph', strict=True)\n",
    "    self.rendering_heatmap_dict = {}\n",
    "    self.num_timesteps = 0\n",
    "    self.total_amount_of_visits = 0\n",
    "    \n",
    "    # Add a node and edge during step function\n",
    "\n",
    "    # Store the amount of visits to a node\n",
    "    # When drawing, convert that to RGB:\n",
    "    \n",
    "    # Node A: 30 visits\n",
    "    # Node B: 1 visit\n",
    "\n",
    "    # Node A: 255, 255, 255\n",
    "    # Node B: 1, 1, 1\n",
    "\n",
    "    # Call the parent constructor, so we can access self.env later\n",
    "    super(FSMRenderingWrapper, self).__init__(env)\n",
    "  \n",
    "  def reset(self):\n",
    "    \"\"\"\n",
    "    Reset the environment \n",
    "    \"\"\"\n",
    "    obs = self.env.reset()\n",
    "\n",
    "    # Add the initial node\n",
    "    if self.env.current_unique_id_state not in self.rendering_heatmap_dict:\n",
    "      self.rendering_heatmap_dict[self.env.current_unique_id_state] = 1\n",
    "\n",
    "      with open(self.env.file_name, 'r') as csv_file:\n",
    "        # pass the file object to DictReader() to get the DictReader object\n",
    "        csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "        # iterate over each line as a ordered dictionary\n",
    "        for row in csv_dict_reader:\n",
    "          # row variable is a dictionary that represents a row in csv\n",
    "          if int(row['Unique_ID']) == self.env.current_unique_id_state:\n",
    "            # print(\"Unique ID in row:\", row['Unique_ID'], \"Self.env.current_unique_id_state:\", self.env.current_unique_id_state)\n",
    "            original_name = row['State_name']\n",
    "            \n",
    "      start_state_name = original_name + \" \" + \"[START STATE]\"\n",
    "\n",
    "      self.rendering_graph.add_node(pydot.Node(name=self.env.current_unique_id_state, label=start_state_name, style=\"filled\", fillcolor=\"white\", fontname=\"Impact\", fontsize='32'))\n",
    "\n",
    "    # else:\n",
    "    #   self.rendering_heatmap_dict[self.env.current_unique_id_state] += 1\n",
    "    #   self.total_amount_of_visits += 1\n",
    "      \n",
    "    return obs\n",
    "\n",
    "  def step(self, action):\n",
    "    \"\"\"\n",
    "    :param action: ([float] or int) Action taken by the agent\n",
    "    :return: (np.ndarray, float, bool, dict) observation, reward, is the episode over?, additional informations\n",
    "    \"\"\"\n",
    "    # Store temporarily current unique id to draw edge\n",
    "    previous_node = self.env.current_unique_id_state\n",
    "\n",
    "    obs, reward, done, info = self.env.step(action)\n",
    "\n",
    "    new_node_found = False\n",
    "\n",
    "    # STORE AMOUNT OF VISITS AT ALL TIMES\n",
    "    # Just create a new node if not in the heatmap dict yet and is not start state id\n",
    "    # wait, no\n",
    "    # actually yes - make it a black void\n",
    "\n",
    "    # if self.env.current_unique_id_state != self.env.start_state_id:\n",
    "    if self.env.current_unique_id_state not in self.rendering_heatmap_dict:\n",
    "      self.rendering_heatmap_dict[self.env.current_unique_id_state] = 1\n",
    "      new_node_found = True\n",
    "    \n",
    "    else:\n",
    "      self.rendering_heatmap_dict[self.env.current_unique_id_state] += 1\n",
    "      self.total_amount_of_visits += 1\n",
    "\n",
    "    with open(self.env.file_name, 'r') as csv_file:\n",
    "      # pass the file object to DictReader() to get the DictReader object\n",
    "      csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "      # iterate over each line as a ordered dictionary\n",
    "      for row in csv_dict_reader:\n",
    "        if int(row['Unique_ID']) == previous_node:\n",
    "          transition_name = row['Transition_names'].split()[action]\n",
    "          \n",
    "        if new_node_found == True:\n",
    "        # row variable is a dictionary that represents a row in csv\n",
    "          if int(row['Unique_ID']) == self.env.current_unique_id_state:\n",
    "            # print(\"Unique ID in row:\", row['Unique_ID'], \"Self.env.current_unique_id_state:\", self.env.current_unique_id_state)\n",
    "            original_name = row['State_name']\n",
    "    \n",
    "    if new_node_found == True:\n",
    "      if self.env.randomize_start_state == True:\n",
    "        if self.env.current_unique_id_state in self.env.start_states:\n",
    "          start_state_name = original_name + \" \" + \"[START STATE]\"\n",
    "          self.rendering_graph.add_node(pydot.Node(name=self.env.current_unique_id_state, label=start_state_name, style=\"filled\", fillcolor=\"white\", fontname=\"Impact\", fontsize='32'))\n",
    "        else:\n",
    "          self.rendering_graph.add_node(pydot.Node(name=self.env.current_unique_id_state, label=original_name, style=\"filled\", fillcolor=\"white\", fontname=\"Impact\", fontsize='32'))\n",
    "      else:\n",
    "        self.rendering_graph.add_node(pydot.Node(name=self.env.current_unique_id_state, label=original_name, style=\"filled\", fillcolor=\"white\", fontname=\"Impact\", fontsize='32'))\n",
    "    \n",
    "    current_node = self.env.current_unique_id_state \n",
    "    # Add edge between previous and current node\n",
    "    self.rendering_graph.add_edge(pydot.Edge(previous_node, current_node, label=transition_name, color='black', fontname=\"Arial\", fontsize='32'))\n",
    "    \n",
    "    self.num_timesteps += 1\n",
    "\n",
    "    if self.num_timesteps % 5000 == 0:\n",
    "      local_max = 0\n",
    "      for node in self.rendering_graph.get_nodes():\n",
    "        if self.rendering_heatmap_dict[int(node.get_name())] > local_max:\n",
    "          local_max = self.rendering_heatmap_dict[int(node.get_name())]\n",
    "          \n",
    "      for node in self.rendering_graph.get_nodes():\n",
    "        amount_of_visits = self.rendering_heatmap_dict[int(node.get_name())]\n",
    "        # Convert the range from 0.0 - local_max to 1.0 - 0.0 for heatmap colouring\n",
    "        # NewValue = (((OldValue - OldMin) * (NewMax - NewMin)) / (OldMax - OldMin)) + NewMin\n",
    "        # Linear something\n",
    "        new_hsv_value = (-amount_of_visits / local_max) + 1.0\n",
    "        node.set_fillcolor(\"0.0 0.0 {}\".format(new_hsv_value))\n",
    "        if new_hsv_value <= 0.5:\n",
    "          node.set_fontcolor(\"white\")\n",
    "\n",
    "        # with open(self.env.file_name, 'r') as csv_file:\n",
    "        #   # pass the file object to DictReader() to get the DictReader object\n",
    "        #   csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "        #   # iterate over each line as a ordered dictionary\n",
    "        #   for row in csv_dict_reader:\n",
    "        #     # row variable is a dictionary that represents a row in csv\n",
    "        #     if row['Unique_ID'] == node.get_name():\n",
    "        #       print(\"Unique ID in row:\", row['Unique_ID'], \"Self.env.current_unique_id_state:\", self.env.current_unique_id_state)\n",
    "        #       node.set_label(row['State_name'] + \" \" + str(self.rendering_heatmap_dict[int(node.get_name())]) + \"/\" + str(self.total_amount_of_visits))\n",
    "              \n",
    "        # node.set_label(self.rendering_heatmap_dict[int(node.get_name())])\n",
    "            \n",
    "      clear_output(wait=True)\n",
    "      plt = Image(self.rendering_graph.create_png())\n",
    "      display(plt)\n",
    "      for k, v in self.rendering_heatmap_dict.items():\n",
    "        with open(self.env.file_name, 'r') as csv_file:\n",
    "          # pass the file object to DictReader() to get the DictReader object\n",
    "          csv_dict_reader = DictReader(csv_file)\n",
    "\n",
    "          # iterate over each line as a ordered dictionary\n",
    "          for row in csv_dict_reader:\n",
    "            if int(row['Unique_ID']) == k:\n",
    "              # print(\"Unique ID in row:\", row['Unique_ID'], \"Self.env.current_unique_id_state:\", self.env.current_unique_id_state)\n",
    "              original_name = row['State_name']\n",
    "        print(original_name, v)\n",
    "\n",
    "    return obs, reward, done, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO, A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "\n",
    "# Instantiate the env\n",
    "env = FSMEnv('pelican.csv', start_state_id=1, use_default_obs_space_limits=False)\n",
    "# wrap it\n",
    "env = make_vec_env(lambda: env, n_envs=1)\n",
    "# env = FSMRenderingWrapper(env)\n",
    "# wrap it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent\n",
    "# You are probably using a MlpPolicy instead of a MultiInputPolicy (cf doc)\n",
    "# AttributeError: 'dict' object has no attribute 'flatten'\n",
    "# model = A2C('MultiInputPolicy', env, gamma=0.99, verbose=1).learn(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "from IPython.display import Image, display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "graph = pydot.Dot(graph_type='digraph', strict=True)\n",
    "\n",
    "graph.add_node(pydot.Node(name=1, style=\"filled\", fillcolor=\"0.0 0.0 0.5\", fontcolor=\"black\"))\n",
    "graph.add_node(pydot.Node(name=2, style=\"filled\", fillcolor=\"0.0 0.0 0.0\"))\n",
    "graph.add_edge(pydot.Edge(1, 3))\n",
    "graph.add_edge(pydot.Edge(1, 4))\n",
    "graph.add_edge(pydot.Edge(2, 4))\n",
    "\n",
    "for node in graph.get_nodes():\n",
    "    print(node.get_label())\n",
    "\n",
    "for edge in graph.get_edges():\n",
    "    print(type(edge.get_source()), type(edge.get_destination()))\n",
    "\n",
    "plt = Image(graph.create_png())\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "from IPython.display import Image, display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "graph = pydot.Dot(graph_type='digraph', strict=True)\n",
    "graph.add_edge(pydot.Edge(\"1\", \"2\"))\n",
    "graph.add_edge(pydot.Edge(\"3\", \"2\"))\n",
    "plt = Image(graph.create_png())\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "from IPython.display import Image, display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "graph = pydot.Dot(graph_type='digraph', strict=True)\n",
    "for i in range(2, 100):\n",
    "    graph.add_edge(pydot.Edge(\"1\", \"{}\".format(i)))\n",
    "    graph.add_edge(pydot.Edge(\"{}\".format(i-1), \"{}\".format(i)))\n",
    "    if i % 50 == 0:\n",
    "        print(\"Aaa\")\n",
    "        # plt = Image(graph.create_png())\n",
    "        # display(plt)\n",
    "        # clear_output(wait=True)\n",
    "graph.write_png(\"Aaa.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2]\n",
    "b = [3, 4]\n",
    "c = [5, 6]\n",
    "\n",
    "for x, y, z in zip(a, b, c):\n",
    "    print(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"ck.txt\", \"w+\")\n",
    "for i in range(10000):\n",
    "    f.write(\"5,S4,0,2,0 1,6 4,5\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.iinfo(np.int32).max)\n",
    "print(np.iinfo(np.int64).max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([1,2,3,4])\n",
    "\n",
    "new = test[1:]\n",
    "np.append(new, 2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6feb42cf36f43b71669a8398d59077f880f7d6df8170b1d736604ffc0ad9a83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('RL_Project': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
